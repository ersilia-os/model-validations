{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c123f11-bad6-45f5-92cf-eb55f79a4941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "DATAPATH = \"../data\"\n",
    "SMICOL = \"smiles\"\n",
    "INCHICOL = \"inchikey\"\n",
    "ACTCOL = \"activity\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faffc095-ef0a-4f4d-85a8-4789f646d642",
   "metadata": {},
   "source": [
    "# Compare Model Training datasets\n",
    "First, we clean up the original files and add the InChiKey of the smiles if not available. We want to create a dataframe with three columns, smiles, inchikey and activity. We will store each dataset under data/model_datasets/{model_name}_processed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a612f3d-374b-44aa-a5b5-ad35d439d677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inchikey eliminated:  0\n"
     ]
    }
   ],
   "source": [
    "#eos21q7\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos21q7\", \"Total_dataset.csv\"))\n",
    "\n",
    "eos21q7 = pd.concat([train_data])\n",
    "\n",
    "inchikeys = []\n",
    "for smi in eos21q7[\"smiles\"]:\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is not None:\n",
    "        inchikey = Chem.MolToInchiKey(mol)\n",
    "    else:\n",
    "        inchikey = None\n",
    "    inchikeys += [inchikey]\n",
    "\n",
    "eos21q7[INCHICOL] = inchikeys\n",
    "total_len = len(eos21q7)\n",
    "eos21q7.dropna(subset=[INCHICOL], inplace=True)\n",
    "print(\"Inchikey eliminated: \", total_len-len(eos21q7))\n",
    "eos21q7.rename(columns={\"smiles\":SMICOL, \"toxicity\":ACTCOL}, inplace=True) #looking at the model, toxicity was chosen for activity\n",
    "eos21q7 = eos21q7[[SMICOL, INCHICOL, ACTCOL]]\n",
    "eos21q7.to_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos21q7_processed.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "185ac370-6b60-4aa4-8826-fb3df8355a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1324378/1689575493.py:3: DtypeWarning: Columns (423,424,425,426,427,428,429,430,431,477,478,479,480,481,482,483,484,485,540,541,542,543,544,545,546,547,548,603,604,605,606,607,608,609,610,611,1012,1013,1050,1052,1074,1083,1084,1121,1123,1145,1217,1218,1219,1220,1222,1223,1224,1226,1227,1229) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_data_with_outcome = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos7e3s\", \"dili_padel_2d.csv\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inchikey eliminated:  0\n"
     ]
    }
   ],
   "source": [
    "#eos7e3s\n",
    "train_data_without_outcome = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos7e3s\", \"dilismiles.csv\"))\n",
    "train_data_with_outcome = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos7e3s\", \"dili_padel_2d.csv\"))\n",
    "\n",
    "##Add the columns together\n",
    "eos7e3s = pd.concat([train_data_without_outcome, train_data_with_outcome], axis=1)\n",
    "\n",
    "inchikeys = []\n",
    "for smi in eos7e3s[\"col_smiles\"]:\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is not None:\n",
    "        inchikey = Chem.MolToInchiKey(mol)\n",
    "    else:\n",
    "        inchikey = None\n",
    "    inchikeys += [inchikey]\n",
    "\n",
    "eos7e3s[INCHICOL] = inchikeys\n",
    "total_len = len(eos7e3s)\n",
    "eos7e3s.dropna(subset=[INCHICOL], inplace=True)\n",
    "print(\"Inchikey eliminated: \", total_len-len(eos7e3s))\n",
    "eos7e3s.rename(columns={\"col_smiles\":SMICOL, \"Outcome\":ACTCOL}, inplace=True) #looking at the model, Outcome was chosen for activity\n",
    "eos7e3s = eos7e3s[[SMICOL, INCHICOL, ACTCOL]]\n",
    "eos7e3s.to_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos7e3s_processed.csv\"), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df00a8c-420c-45fb-a31a-6ec9b17a986f",
   "metadata": {},
   "source": [
    "Once all the datasets have been cleaned, we can compare them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "add68576-7b28-4d88-94cb-430ba66da38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eos21q7:\n",
      "activity\n",
      "1    952\n",
      "0    898\n",
      "Name: count, dtype: int64\n",
      "\n",
      "eos7e3s:\n",
      "activity\n",
      "1    394\n",
      "0    194\n",
      "Name: count, dtype: int64\n",
      "Number of repeated inchikeys in eos21q7: 224\n",
      "Number of repeated inchikeys in eos7e3s: 3\n",
      "Number of repeated inchikeys between eos21q7 and eos7e3s: 555\n"
     ]
    }
   ],
   "source": [
    "models = [\"eos21q7\", \"eos7e3s\"]\n",
    "# load the datasets and make comparisons\n",
    "eos21q7 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos21q7_processed.csv\"))\n",
    "eos7e3s = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos7e3s_processed.csv\"))\n",
    "\n",
    "# proportion of actives and inactives in each dataset\n",
    "print(\"eos21q7:\")\n",
    "print(eos21q7['activity'].value_counts())\n",
    "\n",
    "print(\"\\neos7e3s:\")\n",
    "print(eos7e3s['activity'].value_counts())\n",
    "\n",
    "# number of repeated inchikey between models\n",
    "# Check repeated inchikey within each dataset\n",
    "repeated_inchikey_eos21q7 = eos21q7['inchikey'].duplicated().sum()\n",
    "repeated_inchikey_eos7e3s = eos7e3s['inchikey'].duplicated().sum()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of repeated inchikeys in eos21q7: {repeated_inchikey_eos21q7}\")\n",
    "print(f\"Number of repeated inchikeys in eos7e3s: {repeated_inchikey_eos7e3s}\")\n",
    "\n",
    "# Check repeated inchikey between pairs of datasets\n",
    "repeated_inchikey_eos21q7_eos7e3s = pd.concat([eos21q7['inchikey'], eos7e3s['inchikey']]).duplicated().sum()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of repeated inchikeys between eos21q7 and eos7e3s: {repeated_inchikey_eos21q7_eos7e3s}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "958fb6a9-372a-4c57-9d1f-f4a56c5ad068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage overlap for ../data/model_datasets/eos21q7_processed.csv with all models: 17.73%\n",
      "Percentage overlap for ../data/model_datasets/eos7e3s_processed.csv with all models: 55.78%\n",
      "Percentage overlap between ../data/model_datasets/eos21q7_processed.csv and ../data/model_datasets/eos7e3s_processed.csv: 55.78%\n"
     ]
    }
   ],
   "source": [
    "## Get the percentage overlap between models\n",
    "\n",
    "# Define the dataset paths\n",
    "datasets = [\n",
    "    {'path': '../data/model_datasets/eos21q7_processed.csv'},\n",
    "    {'path': '../data/model_datasets/eos7e3s_processed.csv'}\n",
    "]\n",
    "\n",
    "# Read datasets into a list of DataFrames\n",
    "dfs = [pd.read_csv(dataset['path']) for dataset in datasets]\n",
    "\n",
    "# Dictionary to store the results\n",
    "overlap_results = {}\n",
    "\n",
    "# Method 1: Get inchi keys common to ALL the models' datasets\n",
    "common_keys = set.intersection(*(set(df['inchikey']) for df in dfs))\n",
    "total_common_molecules = len(common_keys)\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    total_molecules = len(df)\n",
    "    percentage_overlap = (total_common_molecules / total_molecules) * 100\n",
    "    overlap_results[f\"Percentage overlap for {datasets[i]['path']} with all models\"] = percentage_overlap\n",
    "\n",
    "# Method 2: Pairwise percentage overlap\n",
    "for i in range(len(dfs)):\n",
    "    for j in range(i + 1, len(dfs)):\n",
    "        common_keys_pairwise = set.intersection(set(dfs[i]['inchikey']), set(dfs[j]['inchikey']))\n",
    "        total_molecules_i = len(dfs[i])\n",
    "        total_molecules_j = len(dfs[j])\n",
    "        percentage_overlap_pairwise = (len(common_keys_pairwise) / min(total_molecules_i, total_molecules_j)) * 100\n",
    "        overlap_results[f\"Percentage overlap between {datasets[i]['path']} and {datasets[j]['path']}\"] = percentage_overlap_pairwise\n",
    "\n",
    "# Display the results\n",
    "for key, value in overlap_results.items():\n",
    "    print(f\"{key}: {value:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb0ae9a-357d-4946-bd19-d8b5ba77bf40",
   "metadata": {},
   "source": [
    "# Build test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82436331-c977-4351-8783-88a33fc5e791",
   "metadata": {},
   "source": [
    " Our first test dataset is the TDC dili dataset from https://tdcommons.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecdd2c25-c8a2-462b-9e56-9e723ba97b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1324378/2695865619.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  tdc_dataset = pd.read_csv(os.path.join(DATAPATH, \"test_data\", \"dili_tdc_dataset.csv\"), sep='\\,')\n"
     ]
    }
   ],
   "source": [
    "tdc_dataset = pd.read_csv(os.path.join(DATAPATH, \"test_data\", \"dili_tdc_dataset.csv\"), sep='\\,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c557b82-7fd8-4823-b2cc-efd3e39525ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Drug_ID', 'Drug', 'Y'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdc_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3990d00-8e4b-429c-8456-d5ddaa279c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INchikey eliminated:  0\n"
     ]
    }
   ],
   "source": [
    "#merge and remove duplicates. Obtain InChiKeys for all\n",
    "# Rename the \"Drug\" column to \"smiles\"\n",
    "tdc_dataset.rename(columns={\"Drug\": \"smiles\", \"Y\": \"activity\"}, inplace=True)\n",
    "\n",
    "# List to store InChiKeys\n",
    "inchikeys = []\n",
    "for smi in tdc_dataset[\"smiles\"]:\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is not None:\n",
    "        inchikey = Chem.MolToInchiKey(mol)\n",
    "    else:\n",
    "        inchikey = None\n",
    "    inchikeys.append(inchikey)\n",
    "\n",
    "# Add the InChiKeys to the dataset\n",
    "tdc_dataset[INCHICOL] = inchikeys\n",
    "\n",
    "# Drop rows with missing InChiKeys\n",
    "tdc_dataset.dropna(subset=[INCHICOL], inplace=True)\n",
    "\n",
    "# Remove duplicates based on \"inchikey\" column\n",
    "total_len = len(tdc_dataset)\n",
    "tdc_dataset.drop_duplicates(subset=[\"inchikey\"], inplace=True)\n",
    "print(\"INchikey eliminated: \", total_len - len(tdc_dataset))\n",
    "\n",
    "# Assuming you want to reorder the columns\n",
    "tdc_dataset_processed = tdc_dataset[[SMICOL, INCHICOL, ACTCOL]]\n",
    "\n",
    "# Saving the processed dataset to a CSV file\n",
    "output_file = os.path.join(\"../data\", \"test_data\", \"tdc_dataset_processed.csv\")\n",
    "tdc_dataset_processed.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00c2db34-4448-44d5-8191-58d7b84225eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                smiles  \\\n",
      "0                                 CC(=O)OCC[N+](C)(C)C   \n",
      "1                                C[N+](C)(C)CC(=O)[O-]   \n",
      "2         O=C(NC(CO)C(O)c1ccc([N+](=O)[O-])cc1)C(Cl)Cl   \n",
      "3                                      O=C(O)c1ccccc1O   \n",
      "4                       CC(NC(C)(C)C)C(=O)c1cccc(Cl)c1   \n",
      "..                                                 ...   \n",
      "470           CCCC(CCC)C(=O)O.CCCC(CCC)C(=O)[O-].[Na+]   \n",
      "471  CCCCC(CC)COC(=O)CC(C(=O)OCC(CC)CCCC)S(=O)(=O)[...   \n",
      "472  C=C1c2cccc(O)c2C(O)=C2C(=O)C3(O)C(O)=C(C(N)=O)...   \n",
      "473                             O=C1OC(C(O)CO)C(O)=C1O   \n",
      "474  CN(C)C1C(=O)C(C(N)=O)=C(O)C2(O)C(=O)C3=C(O)c4c...   \n",
      "\n",
      "                        inchikey  activity  \n",
      "0    OIPILFWXSMYKGL-UHFFFAOYSA-N       0.0  \n",
      "1    KWIUHFFTVRNATP-UHFFFAOYSA-N       0.0  \n",
      "2    WIIZWVCIJKGZOK-UHFFFAOYSA-N       0.0  \n",
      "3    YGSDEFSMJLZEOE-UHFFFAOYSA-N       0.0  \n",
      "4    SNPPWIUOZRMYNY-UHFFFAOYSA-N       0.0  \n",
      "..                           ...       ...  \n",
      "470  MSRILKIQRXUYCT-UHFFFAOYSA-M       1.0  \n",
      "471  APSBXTVYXVQYAB-UHFFFAOYSA-M       0.0  \n",
      "472  XIYOPDCBBDCGOE-UHFFFAOYSA-N       1.0  \n",
      "473  CIWBSHSKHKDKBQ-UHFFFAOYSA-N       0.0  \n",
      "474  GUXHBMASAHGULD-UHFFFAOYSA-N       1.0  \n",
      "\n",
      "[475 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tdc_dataset_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a7de7bac-9475-486c-989d-794a7613db79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed inchikey: 473\n"
     ]
    }
   ],
   "source": [
    "## Now that we have arranged the tdc dataset in smiles_inchikey_activity\n",
    "## we can  eliminate duplicated molecules with training set\n",
    "\n",
    "# load the datasets and make comparisons\n",
    "eos21q7 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos21q7_processed.csv\"))\n",
    "eos7e3s = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos7e3s_processed.csv\"))\n",
    "\n",
    "## concatenate the training set together\n",
    "training_set = pd.concat([eos21q7, eos7e3s], ignore_index=True)\n",
    "\n",
    "# Save the training set to a CSV file\n",
    "training_set.to_csv(os.path.join(DATAPATH, \"model_datasets\",\"training_set.csv\"), index=False)\n",
    "\n",
    "##Load the test dataset\n",
    "test_dataset= pd.read_csv(os.path.join(DATAPATH, \"test_data\", \"tdc_dataset_processed.csv\")) \n",
    "\n",
    "# Calculate the number of removed InChiKey\n",
    "initial_inchikey_count = len(test_dataset)\n",
    "processed_test_dataset = test_dataset[~test_dataset['inchikey'].isin(training_set['inchikey'])]\n",
    "removed_inchikey_count = initial_inchikey_count - len(processed_test_dataset)\n",
    "\n",
    "# Print the number of removed smiles\n",
    "print(f\"Number of removed inchikey: {removed_inchikey_count}\")\n",
    "\n",
    "# Save the processed test dataset to a file\n",
    "processed_test_dataset.to_csv(os.path.join(DATAPATH, \"test_data\", \"processed_test_dataset.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "085f1ec8-1178-418d-b827-b2c1dfe4fb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common inchikeys between training and test datasets: 0\n",
      "Common inchikey: set()\n"
     ]
    }
   ],
   "source": [
    "## Confirm that the training and test dataset has no Inchikey in common\n",
    "\n",
    "training_set = pd.read_csv(os.path.join(DATAPATH,\"model_datasets\", \"training_set.csv\"))\n",
    "test_set = pd.read_csv(os.path.join(DATAPATH,\"test_data\", \"processed_test_dataset.csv\"))\n",
    "\n",
    "# Check for common inchikeys\n",
    "common_inchikey = set(training_set['inchikey']).intersection(set(test_set['inchikey']))\n",
    "\n",
    "# Print the number of common Inchikey\n",
    "print(f\"Number of common inchikeys between training and test datasets: {len(common_inchikey)}\")\n",
    "\n",
    "print(\"Common inchikey:\", common_inchikey)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
